{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc02175",
   "metadata": {},
   "source": [
    "# Handling imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88377f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Pranay5519\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Pranay5519\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Pranay5519/fraud_detection\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Pranay5519/fraud_detection\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Pranay5519/fraud_detection initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Pranay5519/fraud_detection initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='Pranay5519', repo_name='fraud_detection', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/16 22:20:16 INFO mlflow.tracking.fluent: Experiment with name 'Fraud_Imbalance_Comparison' does not exist. Creating a new experiment.\n",
      "2026/01/16 22:20:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NONE] Precision=0.0138 | Recall=0.9446 | ROC-AUC=0.9749\n",
      "üèÉ View run imbalance_none at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2/runs/b622e8a950204f4daf33cad2788b098f\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/16 22:21:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OVERSAMPLING] Precision=0.0140 | Recall=0.9422 | ROC-AUC=0.9755\n",
      "üèÉ View run imbalance_oversampling at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2/runs/7d7820924e9149b680a73d0f8659c160\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/16 22:22:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ADASYN] Precision=0.0073 | Recall=0.9897 | ROC-AUC=0.9794\n",
      "üèÉ View run imbalance_adasyn at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2/runs/9d3f185c71ac4af88660c5b48d969b5e\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/16 22:22:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNDERSAMPLING] Precision=0.0045 | Recall=0.8990 | ROC-AUC=0.9166\n",
      "üèÉ View run imbalance_undersampling at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2/runs/70787e92cba845d495183d47dbcc2852\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/16 22:48:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SMOTE_ENN] Precision=0.0134 | Recall=0.9440 | ROC-AUC=0.9751\n",
      "üèÉ View run imbalance_smote_enn at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2/runs/7cfbeae49e5f4e81b834756f63b4aa76\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# FRAUD MODEL TRAINING WITH MULTIPLE IMBALANCE TECHNIQUES (MLFLOW)\n",
    "# ==============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, roc_auc_score , classification_report\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# ------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.read_csv(r\"D:\\accredian\\data\\cleaned_fraud.csv\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2. ENCODE CATEGORICAL COLUMN\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DEFINE FEATURES AND TARGET\n",
    "# ------------------------------\n",
    "\n",
    "X = df.drop(columns=['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "# ------------------------------\n",
    "# 4. TRAIN‚ÄìTEST SPLIT\n",
    "# ------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. SCALE FEATURES\n",
    "# ------------------------------\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. EXPERIMENT CONFIG\n",
    "# ------------------------------\n",
    "\n",
    "imbalance_methods = [\n",
    "    \"none\",\n",
    "    \"oversampling\",\n",
    "    \"adasyn\",\n",
    "    \"undersampling\",\n",
    "    \"smote_enn\"\n",
    "]\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Pranay5519/fraud_detection.mlflow\")\n",
    "mlflow.set_experiment(\"Fraud_Imbalance_Comparison\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7. TRAINING FUNCTION\n",
    "# ------------------------------\n",
    "\n",
    "def run_imbalanced_experiment(imbalance_method):\n",
    "\n",
    "    X_train_vec = X_train_scaled.copy()\n",
    "    y_train_vec = y_train.copy()\n",
    "\n",
    "    # ---------- Resampling ----------\n",
    "    if imbalance_method == \"oversampling\":\n",
    "        sampler = SMOTE(random_state=42)\n",
    "        X_train_vec, y_train_vec = sampler.fit_resample(X_train_vec, y_train_vec)\n",
    "\n",
    "    elif imbalance_method == \"adasyn\":\n",
    "        sampler = ADASYN(random_state=42)\n",
    "        X_train_vec, y_train_vec = sampler.fit_resample(X_train_vec, y_train_vec)\n",
    "\n",
    "    elif imbalance_method == \"undersampling\":\n",
    "        sampler = RandomUnderSampler(random_state=42)\n",
    "        X_train_vec, y_train_vec = sampler.fit_resample(X_train_vec, y_train_vec)\n",
    "\n",
    "    elif imbalance_method == \"smote_enn\":\n",
    "        sampler = SMOTEENN(random_state=42)\n",
    "        X_train_vec, y_train_vec = sampler.fit_resample(X_train_vec, y_train_vec)\n",
    "\n",
    "    # ---------- MLflow Run ----------\n",
    "    with mlflow.start_run(run_name=f\"imbalance_{imbalance_method}\"):\n",
    "\n",
    "        mlflow.log_param(\"imbalance_method\", imbalance_method)\n",
    "        mlflow.log_param(\"train_samples\", len(y_train_vec))\n",
    "\n",
    "        # ---------- Model ----------\n",
    "        model = LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\"\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_vec, y_train_vec)\n",
    "\n",
    "        # ---------- Predictions ----------\n",
    "        y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
    "\n",
    "        # ---------- Metrics ----------\n",
    "        precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "        # ---------- Log Metrics ----------\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "         # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "        \n",
    "        # ---------- Log Model ----------\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        print(\n",
    "            f\"[{imbalance_method.upper()}] \"\n",
    "            f\"Precision={precision:.4f} | Recall={recall:.4f} | ROC-AUC={roc_auc:.4f}\"\n",
    "        )\n",
    "\n",
    "# ------------------------------\n",
    "# 8. RUN ALL EXPERIMENTS\n",
    "# ------------------------------\n",
    "\n",
    "for method in imbalance_methods:\n",
    "    run_imbalanced_experiment(method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f019e5f",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f1652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/17 11:39:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '13c4155634864f7680e9011934c853c8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2026/01/17 11:39:04 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
      "2026/01/17 11:39:06 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/17 11:39:14 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run big-snail-156 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/13c4155634864f7680e9011934c853c8\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:39:17,635] A new study created in memory with name: no-name-7c6f2363-40e3-49d8-9f28-06dc85389140\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:39:18 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run inquisitive-calf-876 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/b0147867535746df89f8a59594ece3ac\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:41:05,213] Trial 0 finished with value: 0.8527084601339014 and parameters: {'max_depth': 59, 'min_samples_split': 38, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': {0: 2, 1: 1}}. Best is trial 0 with value: 0.8527084601339014.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:41:06 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run dapper-owl-3 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/1001fbb16e1c4b81bf5f677e894d6324\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:42:20,980] Trial 1 finished with value: 0.8965307364576993 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 37, 'criterion': 'gini', 'class_weight': {0: 2, 1: 1}}. Best is trial 1 with value: 0.8965307364576993.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:42:22 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run polite-croc-481 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/3134e036be204226b07267024226661d\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:43:59,237] Trial 2 finished with value: 0.8910529519172246 and parameters: {'max_depth': 50, 'min_samples_split': 31, 'min_samples_leaf': 47, 'criterion': 'gini', 'class_weight': {0: 2, 1: 1}}. Best is trial 1 with value: 0.8965307364576993.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:44:00 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run unequaled-shrew-216 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/f26ed097b201435f810a42443a70aced\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:45:43,209] Trial 3 finished with value: 0.855143031040779 and parameters: {'max_depth': 48, 'min_samples_split': 36, 'min_samples_leaf': 8, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 1 with value: 0.8965307364576993.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:45:44 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run nervous-hare-446 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/c031bee2df7f4a1fb704595a58969541\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:46:59,709] Trial 4 finished with value: 0.8910529519172246 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 11, 'criterion': 'entropy', 'class_weight': {0: 2, 1: 1}}. Best is trial 1 with value: 0.8965307364576993.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:47:01 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run powerful-asp-157 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/f7a6269743f54eed9272e740e1bbd5a2\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:48:33,655] Trial 5 finished with value: 0.8977480219111381 and parameters: {'max_depth': 40, 'min_samples_split': 46, 'min_samples_leaf': 37, 'criterion': 'gini', 'class_weight': {0: 1, 1: 1}}. Best is trial 5 with value: 0.8977480219111381.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:48:35 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run loud-gull-847 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/d7b810463fda4f149ea4220583d96319\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:50:09,038] Trial 6 finished with value: 0.8892270237370663 and parameters: {'max_depth': 37, 'min_samples_split': 24, 'min_samples_leaf': 27, 'criterion': 'gini', 'class_weight': {0: 1, 1: 1}}. Best is trial 5 with value: 0.8977480219111381.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:50:10 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run resilient-jay-32 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/614dd90b7cc2486fa544a54eae2e1cf8\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:51:45,180] Trial 7 finished with value: 0.8581862446743761 and parameters: {'max_depth': 46, 'min_samples_split': 12, 'min_samples_leaf': 19, 'criterion': 'gini', 'class_weight': {0: 5, 1: 1}}. Best is trial 5 with value: 0.8977480219111381.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:51:46 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run omniscient-yak-835 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/d911e3f1f82a4b8d8f4aa3a7b7c170bf\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:53:25,221] Trial 8 finished with value: 0.928180158247109 and parameters: {'max_depth': 21, 'min_samples_split': 26, 'min_samples_leaf': 32, 'criterion': 'entropy', 'class_weight': {0: 1, 1: 1}}. Best is trial 8 with value: 0.928180158247109.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 11:53:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run suave-cat-244 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/32f5b668745a45dfaea9337c232ef434\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:54:40,617] Trial 9 finished with value: 0.9129640900791236 and parameters: {'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 35, 'criterion': 'gini', 'class_weight': {0: 1, 1: 1}}. Best is trial 8 with value: 0.928180158247109.\n",
      "2026/01/17 11:54:42 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 21, 'min_samples_split': 26, 'min_samples_leaf': 32, 'criterion': 'entropy', 'class_weight': {0: 1, 1: 1}}\n",
      "üèÉ View run DecisionTree_Run at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/16e2028120984a32a6399eba626359de\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.read_csv(r\"D:\\accredian\\data\\cleaned_fraud.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "# ------------------------------\n",
    "# 2. ENCODE CATEGORICAL COLUMN\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DEFINE X AND y\n",
    "# ------------------------------\n",
    "\n",
    "X = df.drop(columns=['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "# ------------------------------\n",
    "# 4. TRAIN‚ÄìTEST SPLIT\n",
    "# ------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. SCALE FEATURES\n",
    "# ------------------------------\n",
    "# (Not required for trees, but kept for consistency)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. SMOTE (TRAIN ONLY)\n",
    "# ------------------------------\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# ------------------------------\n",
    "# 7. MLFLOW + OPTUNA SETUP\n",
    "# ------------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Pranay5519/fraud_detection.mlflow\")\n",
    "mlflow.set_experiment(\"Fraud_DecisionTree_Optuna\")\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# ------------------------------\n",
    "# 8. OPTUNA OBJECTIVE FUNCTION\n",
    "# ------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 60),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 50),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 50),\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        \"class_weight\": trial.suggest_categorical(\n",
    "            \"class_weight\",\n",
    "            [{0: 1, 1: 1}, {0: 2, 1: 1}, {0: 5, 1: 1}]\n",
    "        ),\n",
    "        \n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        model = DecisionTreeClassifier(**params)\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # ---------- Classification Report ----------\n",
    "        classification_rep = classification_report(\n",
    "            y_test, y_test_pred, output_dict=True, zero_division=0\n",
    "        )\n",
    "\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Optuna needs ONE value ‚Üí use fraud-class recall\n",
    "        return classification_rep[\"1\"][\"recall\"]\n",
    "\n",
    "# ------------------------------\n",
    "# 9. RUN OPTUNA STUDY\n",
    "# ------------------------------\n",
    "\n",
    "with mlflow.start_run(run_name=\"DecisionTree_Run\"):\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study.best_params.items()})\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # --------------------------\n",
    "    # 10. TRAIN FINAL MODEL\n",
    "    # --------------------------\n",
    "\n",
    "    final_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "    final_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    y_test_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "    classification_rep = classification_report(\n",
    "        y_test, y_test_pred, output_dict=True, zero_division=0\n",
    "    )\n",
    "\n",
    "    for label, metrics in classification_rep.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"final_{label}_{metric}\", value)\n",
    "\n",
    "    print(\"Best Params:\", best_params)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2f17a",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c119085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/17 12:08:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '359870c6991b496d951cd6ff5d1d5a8f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2026/01/17 12:08:10 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
      "2026/01/17 12:08:13 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/17 12:08:21 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run amusing-newt-722 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3/runs/359870c6991b496d951cd6ff5d1d5a8f\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 12:08:24,134] A new study created in memory with name: no-name-fb02d494-7d66-464b-90bf-1199decdde2e\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 12:08:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run tasteful-wren-836 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/7d43a7394ec94b60b3951d366feb4f63\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2026-01-17 12:12:35,618] Trial 0 failed with parameters: {'n_estimators': 155, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 35, 'max_features': 'log2', 'class_weight': {0: 5, 1: 1}} because of the following error: MemoryError((10167052,), dtype('int64')).\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\_utils.py\", line 109, in __call__\n",
      "    return self.func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 184, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in _fit\n",
      "    classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py\", line 296, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py\", line 407, in _unique1d\n",
      "    imask = np.cumsum(mask) - 1\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py\", line 2914, in cumsum\n",
      "    return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py\", line 54, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 77.6 MiB for an array with shape (10167052,) and data type int64\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_29072\\3968810870.py\", line 91, in objective\n",
      "    model.fit(X_train_bal, y_train_bal)\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 484, in safe_patch_function\n",
      "    patch_function(call_original, *args, **kwargs)\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 182, in patch_with_managed_run\n",
      "    result = patch_function(original, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 1716, in patched_fit\n",
      "    result = fit_impl(original, self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 1462, in fit_mlflow\n",
      "    fit_output = original(self, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n",
      "    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n",
      "    original_fn_result = original_fn(*og_args, **og_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n",
      "    original_result = original(*_og_args, **_og_kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 486, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 91, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 2072, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1682, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1784, in _retrieve\n",
      "    self._raise_error_fast()\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1859, in _raise_error_fast\n",
      "    error_job.get_result(self.timeout)\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 758, in get_result\n",
      "    return self._return_or_raise()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 773, in _return_or_raise\n",
      "    raise self._result\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 77.6 MiB for an array with shape (10167052,) and data type int64\n",
      "[W 2026-01-17 12:12:35,636] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run RandomForest_Run at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/43c59eda09824ffaa3af42aa44318709\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 77.6 MiB for an array with shape (10167052,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\_utils.py\", line 109, in __call__\n    return self.func(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 184, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n    tree._fit(\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in _fit\n    classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py\", line 296, in unique\n    ret = _unique1d(ar, return_index, return_inverse, return_counts,\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py\", line 407, in _unique1d\n    imask = np.cumsum(mask) - 1\n            ^^^^^^^^^^^^^^^\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py\", line 2914, in cumsum\n    return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\accredian\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py\", line 54, in _wrapfunc\n    return bound(*args, **kwds)\n           ^^^^^^^^^^^^^^^^^^^^\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 77.6 MiB for an array with shape (10167052,) and data type int64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(run_name=\u001b[33m\"\u001b[39m\u001b[33mRandomForest_Run\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    114\u001b[39m     study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m     mlflow.log_params({\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m study.best_params.items()})\n\u001b[32m    119\u001b[39m     best_params = study.best_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 91\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(nested=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     90\u001b[39m     model = RandomForestClassifier(**params)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_bal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_bal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     y_test_pred = model.predict(X_test_scaled)\n\u001b[32m     95\u001b[39m     \u001b[38;5;66;03m# ---------- Classification Report ----------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:484\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    482\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:182\u001b[39m, in \u001b[36mwith_managed_run.<locals>.patch_with_managed_run\u001b[39m\u001b[34m(original, *args, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     managed_run = create_managed_run()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     result = \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m managed_run:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:1716\u001b[39m, in \u001b[36m_autolog.<locals>.patched_fit\u001b[39m\u001b[34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001b[39m\n\u001b[32m   1712\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t.should_log():\n\u001b[32m   1713\u001b[39m     \u001b[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001b[39;00m\n\u001b[32m   1714\u001b[39m     \u001b[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001b[39;00m\n\u001b[32m   1715\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER.disable_log_post_training_metrics():\n\u001b[32m-> \u001b[39m\u001b[32m1716\u001b[39m         result = \u001b[43mfit_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1717\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_log_post_training_metrics:\n\u001b[32m   1718\u001b[39m         _AUTOLOGGING_METRICS_MANAGER.register_model(\n\u001b[32m   1719\u001b[39m             \u001b[38;5;28mself\u001b[39m, mlflow.active_run().info.run_id\n\u001b[32m   1720\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:1462\u001b[39m, in \u001b[36m_autolog.<locals>.fit_mlflow\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m   1460\u001b[39m _log_pretraining_metadata(autologging_client, \u001b[38;5;28mself\u001b[39m, X, y_true)\n\u001b[32m   1461\u001b[39m params_logging_future = autologging_client.flush(synchronous=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1462\u001b[39m fit_output = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1463\u001b[39m _log_posttraining_metadata(autologging_client, \u001b[38;5;28mself\u001b[39m, X, y_true, sample_weight)\n\u001b[32m   1464\u001b[39m autologging_client.flush(synchronous=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:475\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m         original_result = original(*_og_args, **_og_kwargs)\n\u001b[32m    473\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:426\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    424\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     original_fn_result = \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:472\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001b[32m    469\u001b[39m     disable_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    470\u001b[39m     reroute_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    471\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     original_result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\accredian\\venv\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 77.6 MiB for an array with shape (10167052,) and data type int64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.read_csv(r\"D:\\accredian\\data\\cleaned_fraud.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "# ------------------------------\n",
    "# 2. ENCODE CATEGORICAL COLUMN\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DEFINE X AND y\n",
    "# ------------------------------\n",
    "\n",
    "X = df.drop(columns=['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "# ------------------------------\n",
    "# 4. TRAIN‚ÄìTEST SPLIT\n",
    "# ------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. SCALE FEATURES\n",
    "# (Not required for RF, kept for consistency)\n",
    "# ------------------------------\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. SMOTE (TRAIN ONLY)\n",
    "# ------------------------------\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# ------------------------------\n",
    "# 7. MLFLOW + OPTUNA SETUP\n",
    "# ------------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Pranay5519/fraud_detection.mlflow\")\n",
    "mlflow.set_experiment(\"Fraud_RandomForest_Optuna\")\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# ------------------------------\n",
    "# 8. OPTUNA OBJECTIVE FUNCTION\n",
    "# ------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 50),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 50),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 50),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "        \"class_weight\": trial.suggest_categorical(\n",
    "            \"class_weight\",\n",
    "            [{0: 1, 1: 1}, {0: 2, 1: 1}, {0: 5, 1: 1}]\n",
    "        ),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # ---------- Classification Report ----------\n",
    "        classification_rep = classification_report(\n",
    "            y_test, y_test_pred, output_dict=True, zero_division=0\n",
    "        )\n",
    "\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Optuna optimization target ‚Üí fraud recall\n",
    "        return classification_rep[\"1\"][\"recall\"]\n",
    "\n",
    "# ------------------------------\n",
    "# 9. RUN OPTUNA STUDY\n",
    "# ------------------------------\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest_Run\"):\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study.best_params.items()})\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # --------------------------\n",
    "    # 10. TRAIN FINAL MODEL\n",
    "    # --------------------------\n",
    "\n",
    "    final_model = RandomForestClassifier(\n",
    "        **best_params,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    final_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    y_test_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "    classification_rep = classification_report(\n",
    "        y_test, y_test_pred, output_dict=True, zero_division=0\n",
    "    )\n",
    "\n",
    "    for label, metrics in classification_rep.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"final_{label}_{metric}\", value)\n",
    "\n",
    "    print(\"Best Params:\", best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
