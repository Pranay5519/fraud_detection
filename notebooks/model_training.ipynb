{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c6069d",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7eca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b53a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Pranay5519\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Pranay5519\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Pranay5519/fraud_detection\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Pranay5519/fraud_detection\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Pranay5519/fraud_detection initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Pranay5519/fraud_detection initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='Pranay5519', repo_name='fraud_detection', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889b4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://dagshub.com/Pranay5519/fraud_detection.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c688121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\accredian\\data\\cleaned_fraud.csv\")\n",
    "df  = df[['step', 'type', 'isFraud', 'isMerchant',\n",
    "       'orig_balance_diff', 'dest_balance_diff', 'log_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15bcbeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/16 15:32:40 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0082918849274eefa75490de8d335162', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2026/01/16 15:32:40 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
      "2026/01/16 15:32:42 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/16 15:32:49 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run exultant-moose-502 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/0/runs/0082918849274eefa75490de8d335162\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/0\n",
      "\n",
      "After SMOTE:\n",
      "isFraud\n",
      "0    5083526\n",
      "1    5083526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# 2. ENCODE CATEGORICAL COLUMN\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DEFINE X AND y\n",
    "# ------------------------------\n",
    "\n",
    "X = df.drop(columns=['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "# ------------------------------\n",
    "# 4. TRAIN‚ÄìTEST SPLIT\n",
    "# ------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. SCALE FEATURES\n",
    "# ------------------------------\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. UNDERSAMPLE (TRAINING DATA ONLY)\n",
    "# ------------------------------\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(\n",
    "    sampling_strategy='auto',\n",
    "    random_state=42,\n",
    "    k_neighbors=5\n",
    ")\n",
    "\n",
    "X_train_bal, y_train_bal = smote.fit_resample(\n",
    "    X_train_scaled,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(y_train_bal.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f0625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 7. TRAIN MODEL (PRECISION-FOCUSED)\n",
    "# ------------------------------\n",
    "\n",
    "class_weight = {0: 50, 1: 10}\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs',\n",
    "    class_weight=class_weight\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b978bfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/16 15:34:05 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2026/01/16 15:34:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9987    1.0000    0.9994   1270881\n",
      "           1     0.0000    0.0000    0.0000      1643\n",
      "\n",
      "    accuracy                         0.9987   1272524\n",
      "   macro avg     0.4994    0.5000    0.4997   1272524\n",
      "weighted avg     0.9974    0.9987    0.9981   1272524\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run test run 3 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/0/runs/7ecd27e423c7414aac30dcad2ab46574\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 7. START MLFLOW RUN\n",
    "mlflow.sklearn.autolog()\n",
    "mlflow.set_experiment(\"Fraud_Detection_LogisticRegression\")\n",
    "with mlflow.start_run(run_name=\"test run 3\"):\n",
    "\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_proba = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    threshold = 0.9\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # --------------------------\n",
    "    # 8. METRICS\n",
    "    # --------------------------\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    # --------------------------\n",
    "    # 9. LOG PARAMETERS\n",
    "    # --------------------------\n",
    "\n",
    "    mlflow.log_param(\"model\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"class_weight\", class_weight)\n",
    "    mlflow.log_param(\"threshold\", threshold)\n",
    "\n",
    "    # --------------------------\n",
    "    # 10. LOG METRICS\n",
    "    # --------------------------\n",
    "\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "    # --------------------------\n",
    "    # 11. LOG MODEL\n",
    "    # --------------------------\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, \"model\")\n",
    "\n",
    "    print(\"Run logged to MLflow\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019f2c5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3bdc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/17 12:46:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '7630b52f00cc46ba97e506dbb555bfd0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2026/01/17 12:46:58 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
      "2026/01/17 12:46:59 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/17 12:47:06 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run stately-robin-891 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/7630b52f00cc46ba97e506dbb555bfd0\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 12:47:10,881] A new study created in memory with name: no-name-068e0489-8210-4ef5-867b-8608bde3e1e8\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 12:47:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:48:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:49:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run able-shoat-468 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/70950feba32845e78d6c118afa4e1418\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 12:49:26,867] Trial 0 finished with value: 0.8618381010346926 and parameters: {'max_depth': 86, 'min_samples_split': 39, 'min_samples_leaf': 5, 'criterion': 'gini', 'class_weight': {0: 10, 1: 1}}. Best is trial 0 with value: 0.8618381010346926.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 12:49:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:50:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:51:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run caring-ape-86 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/69ec06fef9724af7b5eeee9cf988cdb0\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 12:51:39,491] Trial 1 finished with value: 0.8587948874010956 and parameters: {'max_depth': 24, 'min_samples_split': 83, 'min_samples_leaf': 10, 'criterion': 'gini', 'class_weight': {0: 10, 1: 1}}. Best is trial 0 with value: 0.8618381010346926.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 12:52:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:53:06 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:53:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run abrasive-moth-873 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/dbe9a8205e0a49a581f8358da63ae447\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 12:53:53,011] Trial 2 finished with value: 0.8727936701156421 and parameters: {'max_depth': 144, 'min_samples_split': 46, 'min_samples_leaf': 32, 'criterion': 'entropy', 'class_weight': {0: 7, 1: 1}}. Best is trial 2 with value: 0.8727936701156421.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 12:54:25 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:55:16 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:55:53 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run learned-gnat-865 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/e65886c4111b4c61a0736ec009b86d77\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 12:56:01,801] Trial 3 finished with value: 0.8788800973828362 and parameters: {'max_depth': 15, 'min_samples_split': 45, 'min_samples_leaf': 31, 'criterion': 'entropy', 'class_weight': {0: 12, 1: 1}}. Best is trial 3 with value: 0.8788800973828362.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 12:56:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:57:28 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:58:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run calm-snake-758 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/aae83c0f307241399986aa004e4cc55f\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 12:58:14,116] Trial 4 finished with value: 0.8667072428484479 and parameters: {'max_depth': 31, 'min_samples_split': 38, 'min_samples_leaf': 14, 'criterion': 'entropy', 'class_weight': {0: 10, 1: 1}}. Best is trial 3 with value: 0.8788800973828362.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 12:58:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 12:59:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:00:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run spiffy-midge-120 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/3fd31ad6c2e74117a88b9ecfc5113516\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:00:26,275] Trial 5 finished with value: 0.8800973828362751 and parameters: {'max_depth': 66, 'min_samples_split': 87, 'min_samples_leaf': 37, 'criterion': 'gini', 'class_weight': {0: 5, 1: 1}}. Best is trial 5 with value: 0.8800973828362751.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:00:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:01:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:02:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run vaunted-dog-33 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/b3cbfc6d2fd045468de44d4cca46caa8\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:02:38,226] Trial 6 finished with value: 0.8648813146682898 and parameters: {'max_depth': 97, 'min_samples_split': 78, 'min_samples_leaf': 14, 'criterion': 'entropy', 'class_weight': {0: 10, 1: 1}}. Best is trial 5 with value: 0.8800973828362751.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:03:11 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:04:03 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:04:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run fortunate-frog-71 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/994e1c8564df4ff885a919b5c8eed864\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:04:49,674] Trial 7 finished with value: 0.877054169202678 and parameters: {'max_depth': 69, 'min_samples_split': 72, 'min_samples_leaf': 20, 'criterion': 'gini', 'class_weight': {0: 5, 1: 1}}. Best is trial 5 with value: 0.8800973828362751.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:05:22 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:06:15 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:06:53 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run honorable-grub-212 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/7a1a34007a9947a08c063dec5829afba\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:07:01,701] Trial 8 finished with value: 0.8557516737674985 and parameters: {'max_depth': 109, 'min_samples_split': 49, 'min_samples_leaf': 9, 'criterion': 'gini', 'class_weight': {0: 12, 1: 1}}. Best is trial 5 with value: 0.8800973828362751.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:07:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:08:25 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:09:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run wise-donkey-635 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/9ac7a88cf46f435cba693ab7fa1dfdd0\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:09:12,752] Trial 9 finished with value: 0.8691418137553256 and parameters: {'max_depth': 45, 'min_samples_split': 55, 'min_samples_leaf': 14, 'criterion': 'gini', 'class_weight': {0: 7, 1: 1}}. Best is trial 5 with value: 0.8800973828362751.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:09:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:10:36 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:11:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run unique-chimp-344 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/93aca319567f425d97200beafcc89cf6\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:11:22,264] Trial 10 finished with value: 0.8782714546561169 and parameters: {'max_depth': 62, 'min_samples_split': 99, 'min_samples_leaf': 40, 'criterion': 'gini', 'class_weight': {0: 5, 1: 1}}. Best is trial 5 with value: 0.8800973828362751.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:11:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:12:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:13:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run mysterious-seal-26 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/a6b11f790d004bf283740f9c8079a337\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:13:31,693] Trial 11 finished with value: 0.8660986001217286 and parameters: {'max_depth': 18, 'min_samples_split': 62, 'min_samples_leaf': 31, 'criterion': 'entropy', 'class_weight': {0: 12, 1: 1}}. Best is trial 5 with value: 0.8800973828362751.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:14:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:14:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:15:36 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bedecked-bug-33 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/0af9b2a332044a419022d11962b485cf\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:15:45,188] Trial 12 finished with value: 0.8849665246500305 and parameters: {'max_depth': 49, 'min_samples_split': 92, 'min_samples_leaf': 32, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:16:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:17:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:17:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run salty-foal-808 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/745f00d34c9f4d10a5a755a68c770813\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:17:59,356] Trial 13 finished with value: 0.8831405964698722 and parameters: {'max_depth': 54, 'min_samples_split': 96, 'min_samples_leaf': 39, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:18:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:19:25 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:20:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run delightful-wren-279 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/82b44d8c60014e98b4dcb9a9e03b86e6\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:20:11,294] Trial 14 finished with value: 0.8800973828362751 and parameters: {'max_depth': 46, 'min_samples_split': 97, 'min_samples_leaf': 24, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:20:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:21:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:22:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run traveling-shark-772 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/ece498bf207b4aa19582e54c47c83da5\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:22:25,870] Trial 15 finished with value: 0.8819233110164334 and parameters: {'max_depth': 46, 'min_samples_split': 91, 'min_samples_leaf': 25, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:22:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:23:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:24:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run welcoming-kit-592 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/895ac65fe77a4901a6b09d61c4bac2cf\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:24:38,827] Trial 16 finished with value: 0.8825319537431527 and parameters: {'max_depth': 115, 'min_samples_split': 73, 'min_samples_leaf': 36, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:25:10 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:26:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:26:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run calm-ox-308 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/01e16ee48b4e4aa9924866aba4e750b1\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:26:50,454] Trial 17 finished with value: 0.8819233110164334 and parameters: {'max_depth': 55, 'min_samples_split': 92, 'min_samples_leaf': 26, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:27:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:28:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:28:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run serious-mole-179 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/b2fb8541c8174a70b704333c7285b135\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:29:02,740] Trial 18 finished with value: 0.8831405964698722 and parameters: {'max_depth': 81, 'min_samples_split': 100, 'min_samples_leaf': 40, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:29:35 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:30:28 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:31:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run upset-sponge-662 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/0c889da81da544efb26fe7df46178fec\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:31:14,109] Trial 19 finished with value: 0.877054169202678 and parameters: {'max_depth': 32, 'min_samples_split': 82, 'min_samples_leaf': 34, 'criterion': 'entropy', 'class_weight': {0: 7, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:31:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:32:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:33:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run luxuriant-kite-909 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/53f40034269341c0b4d7956c69a0014e\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:33:26,459] Trial 20 finished with value: 0.8825319537431527 and parameters: {'max_depth': 78, 'min_samples_split': 64, 'min_samples_leaf': 28, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:33:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:34:53 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:35:32 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run blushing-whale-331 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/56b4c8946ecf466dbf5c9a14fdcbd4eb\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:35:41,077] Trial 21 finished with value: 0.8831405964698722 and parameters: {'max_depth': 81, 'min_samples_split': 100, 'min_samples_leaf': 39, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:36:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:37:07 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:37:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run mercurial-cow-567 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/350c052c461c4fa8bc5c064b8a754758\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:37:53,362] Trial 22 finished with value: 0.8837492391965917 and parameters: {'max_depth': 95, 'min_samples_split': 92, 'min_samples_leaf': 36, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:38:25 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:39:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:39:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run stately-kit-332 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/13df1d45b8ad4fec902a1fb59a2a245a\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:40:07,461] Trial 23 finished with value: 0.8837492391965917 and parameters: {'max_depth': 133, 'min_samples_split': 91, 'min_samples_leaf': 34, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:40:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:41:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:42:11 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run selective-cod-948 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/1bff3570a1c747a2817b43b7c65853de\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:42:20,184] Trial 24 finished with value: 0.8819233110164334 and parameters: {'max_depth': 142, 'min_samples_split': 88, 'min_samples_leaf': 29, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:42:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:43:47 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:44:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run upbeat-horse-510 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/149ea70b002d41d984511af153cddbf9\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:44:35,176] Trial 25 finished with value: 0.8794887401095557 and parameters: {'max_depth': 123, 'min_samples_split': 75, 'min_samples_leaf': 21, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:45:07 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:46:01 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:46:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run able-gull-518 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/8c30d969b9044c02a1f8e2aa7807fe07\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:46:47,364] Trial 26 finished with value: 0.8813146682897139 and parameters: {'max_depth': 132, 'min_samples_split': 83, 'min_samples_leaf': 35, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:47:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:48:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:48:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run unleashed-robin-959 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/29854b93949e43a7bacb7c13bd7ca7c3\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:48:58,029] Trial 27 finished with value: 0.8612294583079733 and parameters: {'max_depth': 95, 'min_samples_split': 91, 'min_samples_leaf': 32, 'criterion': 'entropy', 'class_weight': {0: 12, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:49:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:50:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:50:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run trusting-worm-375 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/b0f937525a944a79b709082303ee8b74\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:51:06,372] Trial 28 finished with value: 0.8709677419354839 and parameters: {'max_depth': 105, 'min_samples_split': 30, 'min_samples_leaf': 21, 'criterion': 'entropy', 'class_weight': {0: 7, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 10, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 7, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 12, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 13:51:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:52:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:53:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run thoughtful-kit-307 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/5c05fddba9454a54822fd9fdadb759a6\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:53:17,887] Trial 29 finished with value: 0.8667072428484479 and parameters: {'max_depth': 133, 'min_samples_split': 70, 'min_samples_leaf': 35, 'criterion': 'entropy', 'class_weight': {0: 10, 1: 1}}. Best is trial 12 with value: 0.8849665246500305.\n",
      "2026/01/17 13:53:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:54:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/01/17 13:55:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\accredian\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 49, 'min_samples_split': 92, 'min_samples_leaf': 32, 'criterion': 'entropy', 'class_weight': {0: 5, 1: 1}}\n",
      "üèÉ View run DecisionTree_Run at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7/runs/e5a8fbf61e04466d8f67d00d4dfb7a61\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.read_csv(r\"D:\\accredian\\data\\cleaned_fraud.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 2. ENCODE CATEGORICAL COLUMN\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DEFINE X AND y\n",
    "# ------------------------------\n",
    "\n",
    "X = df.drop(columns=['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "# ------------------------------\n",
    "# 4. TRAIN‚ÄìTEST SPLIT\n",
    "# ------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. SMOTE (TRAIN ONLY)\n",
    "# ------------------------------\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. MLFLOW + OPTUNA SETUP\n",
    "# ------------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Pranay5519/fraud_detection.mlflow\")\n",
    "mlflow.set_experiment(\"Fraud_DecisionTree_Optuna Exp2\")\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# ------------------------------\n",
    "# 7. OPTUNA OBJECTIVE FUNCTION\n",
    "# ------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 15, 150),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 30, 100),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 40),\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        \"class_weight\": trial.suggest_categorical(\n",
    "            \"class_weight\",\n",
    "            [{0: 5, 1: 1}, {0: 10, 1: 1}, {0: 7, 1: 1},{0: 12, 1: 1}]\n",
    "        ),\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        model = DecisionTreeClassifier(**params)\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # ---------- Classification Report ----------\n",
    "        classification_rep = classification_report(\n",
    "            y_test, y_test_pred, output_dict=True, zero_division=0\n",
    "        )\n",
    "\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Optuna optimization target ‚Üí fraud recall\n",
    "        return classification_rep[\"1\"][\"recall\"]\n",
    "\n",
    "# ------------------------------\n",
    "# 8. RUN OPTUNA STUDY\n",
    "# ------------------------------\n",
    "\n",
    "with mlflow.start_run(run_name=\"DecisionTree_Run\"):\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=30)\n",
    "\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study.best_params.items()})\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # --------------------------\n",
    "    # 9. TRAIN FINAL MODEL\n",
    "    # --------------------------\n",
    "\n",
    "    final_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "    final_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "    classification_rep = classification_report(\n",
    "        y_test, y_test_pred, output_dict=True, zero_division=0\n",
    "    )\n",
    "\n",
    "    for label, metrics in classification_rep.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"final_{label}_{metric}\", value)\n",
    "\n",
    "    print(\"Best Params:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db456627",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963c58e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Pranay5519\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Pranay5519\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Pranay5519/fraud_detection\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Pranay5519/fraud_detection\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Pranay5519/fraud_detection initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Pranay5519/fraud_detection initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='Pranay5519', repo_name='fraud_detection', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd9915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2026-01-16 21:54:03,771] A new study created in memory with name: no-name-3b3d664b-278d-4872-a63d-9bae18476c5a\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/16 21:54:04 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run persistent-seal-209 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/1/runs/ae614334d184440a9fc14014e126ca23\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 21:55:09,340] Trial 0 finished with value: 0.9506688264865168 and parameters: {'C': 0.05892696682793512, 'solver': 'liblinear', 'class_weight': {0: 5, 1: 1}}. Best is trial 0 with value: 0.9506688264865168.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/16 21:55:10 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run chill-steed-658 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/1/runs/bf8aa477128d44f2b97801e97079e0ff\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 21:56:17,137] Trial 1 finished with value: 0.9721546339248937 and parameters: {'C': 0.18614995516565452, 'solver': 'lbfgs', 'class_weight': {0: 5, 1: 1}}. Best is trial 1 with value: 0.9721546339248937.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/16 21:56:17 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run defiant-grouse-645 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/1/runs/0cb4aa3aa314484d8737629ee672884e\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 21:57:15,320] Trial 2 finished with value: 0.9372275226773534 and parameters: {'C': 0.012224662915859554, 'solver': 'lbfgs', 'class_weight': {0: 5, 1: 1}}. Best is trial 1 with value: 0.9721546339248937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC: 0.9721546339248937\n",
      "Best Params: {'C': 0.18614995516565452, 'solver': 'lbfgs', 'class_weight': {0: 5, 1: 1}}\n",
      "üèÉ View run Log-Reg_run at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/1/runs/ba719e181484446fa53b71906dd889fc\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "import tempfile\n",
    "import os\n",
    "# ------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.read_csv(r\"D:\\accredian\\data\\cleaned_fraud.csv\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2. ENCODE CATEGORICAL COLUMN\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DEFINE X AND y\n",
    "# ------------------------------\n",
    "\n",
    "X = df.drop(columns=['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "# ------------------------------\n",
    "# 4. TRAIN‚ÄìTEST SPLIT\n",
    "# ------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. SCALE FEATURES\n",
    "# ------------------------------\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. SMOTE (TRAIN ONLY)\n",
    "# ------------------------------\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "\n",
    "X_train_bal, y_train_bal = smote.fit_resample(\n",
    "    X_train_scaled,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 7. MLFLOW + OPTUNA SETUP\n",
    "# ------------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Pranay5519/fraud_detection.mlflow\")\n",
    "mlflow.set_experiment(\"Fraud_LogReg_Optuna\")\n",
    "\n",
    "mlflow.sklearn.autolog(disable=False)\n",
    "\n",
    "# ------------------------------\n",
    "# 8. OPTUNA OBJECTIVE FUNCTION\n",
    "# ------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"C\": trial.suggest_float(\"C\", 0.001, 10.0, log=True),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"lbfgs\", \"liblinear\"]),\n",
    "        \"class_weight\": trial.suggest_categorical(\n",
    "            \"class_weight\",\n",
    "            [{0: 1, 1: 1}, {0: 2, 1: 1}, {0: 5, 1: 1}]\n",
    "        ),\n",
    "        \"max_iter\": 1000\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        model = LogisticRegression(**params)\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "        # ---------- Predictions ----------\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "        # ---------- Metrics ----------\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # ---------- Log metrics ----------\n",
    "        mlflow.log_metric(\"test_roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"test_precision\", precision)\n",
    "        mlflow.log_metric(\"test_recall\", recall)\n",
    "        mlflow.log_metric(\"test_f1_score\", f1)\n",
    "\n",
    "        # ---------- Confusion Matrix ----------\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # ---------- Save artifacts ----------\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            cm_path = os.path.join(tmpdir, \"confusion_matrix.txt\")\n",
    "            cr_path = os.path.join(tmpdir, \"classification_report.txt\")\n",
    "\n",
    "            with open(cm_path, \"w\") as f:\n",
    "                f.write(str(cm))\n",
    "\n",
    "            with open(cr_path, \"w\") as f:\n",
    "                f.write(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "            mlflow.log_artifact(cm_path)\n",
    "            mlflow.log_artifact(cr_path)\n",
    "\n",
    "        return roc_auc\n",
    "# ------------------------------\n",
    "# 9. RUN OPTUNA STUDY\n",
    "# ------------------------------\n",
    "\n",
    "with mlflow.start_run(run_name=\"Log-Reg_run\"):\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=3)\n",
    "\n",
    "    mlflow.log_params(\n",
    "        {f\"best_{k}\": v for k, v in study.best_params.items()}\n",
    "    )\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    final_model = LogisticRegression(\n",
    "                                **best_params,\n",
    "                                max_iter=1000\n",
    "                                    )\n",
    "\n",
    "    final_model.fit(X_train_bal, y_train_bal)\n",
    "    \n",
    "    # Train\n",
    "    y_train_proba = final_model.predict_proba(X_train_scaled)[:, 1]\n",
    "    y_train_pred = (y_train_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Test\n",
    "    y_test_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
    "    metrics = {\n",
    "                # TRAIN\n",
    "                \"train_precision\": precision_score(y_train, y_train_pred, zero_division=0),\n",
    "                \"train_recall\": recall_score(y_train, y_train_pred, zero_division=0),\n",
    "                \"train_f1\": f1_score(y_train, y_train_pred, zero_division=0),\n",
    "                \"train_roc_auc\": roc_auc_score(y_train, y_train_proba),\n",
    "\n",
    "                # TEST\n",
    "                \"test_precision\": precision_score(y_test, y_test_pred, zero_division=0),\n",
    "                \"test_recall\": recall_score(y_test, y_test_pred, zero_division=0),\n",
    "                \"test_f1\": f1_score(y_test, y_test_pred, zero_division=0),\n",
    "                \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "                }\n",
    "    for k, v in metrics.items():\n",
    "        mlflow.log_metric(k, v)\n",
    "        \n",
    "    mlflow.log_metric(\"best_roc_auc\", study.best_value)\n",
    "\n",
    "    print(\"Best ROC-AUC:\", study.best_value)\n",
    "    print(\"Best Params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3f481",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d5842b0",
   "metadata": {},
   "source": [
    "# Random Forest Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2590a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Pranay5519\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Pranay5519\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Pranay5519/fraud_detection\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Pranay5519/fraud_detection\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Pranay5519/fraud_detection initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Pranay5519/fraud_detection initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='Pranay5519', repo_name='fraud_detection', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541377fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026/01/17 09:25:35 INFO mlflow.tracking.fluent: Experiment with name 'Fraud_RandomForest_Optuna' does not exist. Creating a new experiment.\n",
      "[I 2026-01-17 09:25:37,363] A new study created in memory with name: no-name-5659941a-2993-4da3-a865-9bcc4385b8da\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:25:37 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run valuable-ray-410 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/313d7f19facd4e7a97fbff4c2c891f1c\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:26:06,866] Trial 0 finished with value: 0.03346670770493485 and parameters: {'n_estimators': 104, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'class_weight': {0: 2, 1: 1}}. Best is trial 0 with value: 0.03346670770493485.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:26:07 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run merciful-moose-52 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/471e60c77fe04878b4b5ee36ae45367b\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:26:44,807] Trial 1 finished with value: 0.09868967721316714 and parameters: {'n_estimators': 280, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'class_weight': {0: 5, 1: 1}}. Best is trial 1 with value: 0.09868967721316714.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:26:45 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run sedate-tern-569 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/a18b8a235dd24805b6803367c1f5ddfe\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:27:22,793] Trial 2 finished with value: 0.06648374841705361 and parameters: {'n_estimators': 320, 'max_depth': 19, 'min_samples_split': 19, 'min_samples_leaf': 3, 'max_features': 'log2', 'class_weight': {0: 5, 1: 1}}. Best is trial 1 with value: 0.09868967721316714.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:27:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run merciful-smelt-885 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/4e381f24606c4629a42186ae2d9a8fa8\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:28:00,788] Trial 3 finished with value: 0.05413569561823304 and parameters: {'n_estimators': 146, 'max_depth': 27, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': {0: 5, 1: 1}}. Best is trial 1 with value: 0.09868967721316714.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:28:01 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run angry-smelt-183 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/91428354859948bc8260766b854ddd96\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:28:38,831] Trial 4 finished with value: 0.09791983764586504 and parameters: {'n_estimators': 287, 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'class_weight': {0: 5, 1: 1}}. Best is trial 1 with value: 0.09868967721316714.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:28:39 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run worried-crow-266 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/3863338db9684c23b12b9e1eec0e881f\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:29:16,790] Trial 5 finished with value: 0.10067991631799163 and parameters: {'n_estimators': 288, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 16, 'max_features': 'log2', 'class_weight': {0: 5, 1: 1}}. Best is trial 5 with value: 0.10067991631799163.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:29:17 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run polite-ape-646 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/9f5378ae11e44948ad8e8cde474b5b4b\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:29:54,859] Trial 6 finished with value: 0.06324348139544199 and parameters: {'n_estimators': 236, 'max_depth': 29, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'class_weight': {0: 5, 1: 1}}. Best is trial 5 with value: 0.10067991631799163.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:29:55 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run illustrious-hare-319 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/2399b894ea1d47ac965383cec11b96ef\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:30:32,825] Trial 7 finished with value: 0.031079131227217498 and parameters: {'n_estimators': 349, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2', 'class_weight': {0: 1, 1: 1}}. Best is trial 5 with value: 0.10067991631799163.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:30:33 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run carefree-toad-427 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/d1e3ed54320a4dd6805c1cf91f7b8e2a\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:31:10,811] Trial 8 finished with value: 0.03313840155945419 and parameters: {'n_estimators': 239, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'class_weight': {0: 2, 1: 1}}. Best is trial 5 with value: 0.10067991631799163.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "2026/01/17 09:31:11 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run brawny-roo-990 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/d2fa2fe8d16348c7b0648ce8546f7992\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 09:31:48,834] Trial 9 finished with value: 0.033398901729366444 and parameters: {'n_estimators': 299, 'max_depth': 27, 'min_samples_split': 19, 'min_samples_leaf': 12, 'max_features': 'log2', 'class_weight': {0: 2, 1: 1}}. Best is trial 5 with value: 0.10067991631799163.\n",
      "2026/01/17 09:31:50 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 288, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 16, 'max_features': 'log2', 'class_weight': {0: 5, 1: 1}}\n",
      "üèÉ View run RandomForest_Run at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4/runs/a0632fefa7fb430a8b7c97b952392c24\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# ------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.read_csv(r\"D:\\accredian\\data\\cleaned_fraud.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "# ------------------------------\n",
    "# 2. ENCODE CATEGORICAL COLUMN\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DEFINE X AND y\n",
    "# ------------------------------\n",
    "\n",
    "X = df.drop(columns=['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "# ------------------------------\n",
    "# 4. TRAIN‚ÄìTEST SPLIT\n",
    "# ------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. SCALE FEATURES\n",
    "# (Not required for RF, kept for consistency)\n",
    "# ------------------------------\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. UNDERSAMPLING (TRAIN ONLY)\n",
    "# ------------------------------\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_bal, y_train_bal = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# ------------------------------\n",
    "# 7. MLFLOW SETUP\n",
    "# ------------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Pranay5519/fraud_detection.mlflow\")\n",
    "mlflow.set_experiment(\"Fraud_RandomForest_Optuna\")\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# ------------------------------\n",
    "# 8. OPTUNA OBJECTIVE FUNCTION\n",
    "# ------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 400),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "        \"class_weight\": trial.suggest_categorical(\n",
    "            \"class_weight\",\n",
    "            [{0: 1, 1: 1}, {0: 2, 1: 1}, {0: 5, 1: 1}]\n",
    "        ),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # ---------- Classification Report ----------\n",
    "        report = classification_report(\n",
    "            y_test, y_test_pred, output_dict=True, zero_division=0\n",
    "        )\n",
    "\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Optuna optimization target ‚Üí fraud recall\n",
    "        return report[\"1\"][\"precision\"]\n",
    "\n",
    "# ------------------------------\n",
    "# 9. RUN OPTUNA STUDY\n",
    "# ------------------------------\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest_Run\"):\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study.best_params.items()})\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # --------------------------\n",
    "    # 10. TRAIN FINAL MODEL\n",
    "    # --------------------------\n",
    "\n",
    "    final_model = RandomForestClassifier(\n",
    "        **best_params,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    final_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    y_test_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "    final_report = classification_report(\n",
    "        y_test, y_test_pred, output_dict=True, zero_division=0\n",
    "    )\n",
    "\n",
    "    for label, metrics in final_report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"final_{label}_{metric}\", value)\n",
    "\n",
    "    print(\"Best Params:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef86e12",
   "metadata": {},
   "source": [
    "# LightGBM SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065b43ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/17 11:01:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd512a8c55c7e4507b78dd7f7fd47254d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2026/01/17 11:01:35 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
      "2026/01/17 11:01:37 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/17 11:01:45 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run capable-mink-743 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/d512a8c55c7e4507b78dd7f7fd47254d\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:01:48,651] A new study created in memory with name: no-name-1cf677bf-f698-4636-970f-7879848f0875\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:02:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run mysterious-dove-850 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/25854e13db8247cfb8a9d81a5161ddd0\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:03:07,636] Trial 0 finished with value: 0.07716718675622786 and parameters: {'n_estimators': 342, 'learning_rate': 0.15841451215292526, 'num_leaves': 160, 'max_depth': 45, 'min_child_samples': 13, 'subsample': 0.919851528253562, 'colsample_bytree': 0.991492713185355, 'class_weight': {0: 1, 1: 1}}. Best is trial 0 with value: 0.07716718675622786.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.209334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:05:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run fun-quail-374 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/470b58efeb64498f939ee9db1ce12e7d\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:06:20,580] Trial 1 finished with value: 0.12331313131313132 and parameters: {'n_estimators': 351, 'learning_rate': 0.034731791232880525, 'num_leaves': 85, 'max_depth': 67, 'min_child_samples': 72, 'subsample': 0.8911265000421036, 'colsample_bytree': 0.9436933529536189, 'class_weight': {0: 2, 1: 1}}. Best is trial 1 with value: 0.12331313131313132.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:07:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run nervous-hare-501 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/e499975026e44a79a2d13b761bff433c\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:08:07,309] Trial 2 finished with value: 0.02540640187699011 and parameters: {'n_estimators': 483, 'learning_rate': 0.18346022024708822, 'num_leaves': 293, 'max_depth': 65, 'min_child_samples': 90, 'subsample': 0.7780903609942215, 'colsample_bytree': 0.7583931359332616, 'class_weight': {0: 1, 1: 1}}. Best is trial 1 with value: 0.12331313131313132.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:09:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run illustrious-hawk-851 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/544f85fb72794d8c9860300af32a8416\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:10:06,140] Trial 3 finished with value: 0.09579905260533533 and parameters: {'n_estimators': 488, 'learning_rate': 0.011207119889774896, 'num_leaves': 266, 'max_depth': 44, 'min_child_samples': 11, 'subsample': 0.7328226220833365, 'colsample_bytree': 0.917246380557865, 'class_weight': {0: 1, 1: 1}}. Best is trial 1 with value: 0.12331313131313132.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:10:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run peaceful-skink-475 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/f0f3403241874337962a23cbdeeda65b\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:10:47,188] Trial 4 finished with value: 0.11067165252409032 and parameters: {'n_estimators': 136, 'learning_rate': 0.2845745044028196, 'num_leaves': 26, 'max_depth': 66, 'min_child_samples': 55, 'subsample': 0.6479561945004498, 'colsample_bytree': 0.6112982895497147, 'class_weight': {0: 2, 1: 1}}. Best is trial 1 with value: 0.12331313131313132.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:11:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run fearless-wren-659 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/2d0dcdcc4ba34aeab6972118e15661f2\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:11:40,008] Trial 5 finished with value: 0.14632921562719695 and parameters: {'n_estimators': 187, 'learning_rate': 0.21598599268734434, 'num_leaves': 181, 'max_depth': 64, 'min_child_samples': 22, 'subsample': 0.7853546892128662, 'colsample_bytree': 0.8106367265956919, 'class_weight': {0: 2, 1: 1}}. Best is trial 5 with value: 0.14632921562719695.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:12:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run peaceful-horse-351 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/b14c0847552c4603882b35633844996e\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:12:52,561] Trial 6 finished with value: 0.21382228490832159 and parameters: {'n_estimators': 398, 'learning_rate': 0.024682514555689226, 'num_leaves': 29, 'max_depth': 40, 'min_child_samples': 66, 'subsample': 0.9507498403160686, 'colsample_bytree': 0.7522316232813369, 'class_weight': {0: 5, 1: 1}}. Best is trial 6 with value: 0.21382228490832159.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:13:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run efficient-rook-898 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/4d052fd6d271468697757527cfc61dc9\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:14:17,943] Trial 7 finished with value: 0.09100917431192661 and parameters: {'n_estimators': 400, 'learning_rate': 0.12248796399646412, 'num_leaves': 247, 'max_depth': 9, 'min_child_samples': 100, 'subsample': 0.9513842034832898, 'colsample_bytree': 0.6680703971720567, 'class_weight': {0: 2, 1: 1}}. Best is trial 6 with value: 0.21382228490832159.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:15:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run rogue-pug-836 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/45cc5097eb84442586de42e64c934eb7\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:16:07,945] Trial 8 finished with value: 0.0216337187616561 and parameters: {'n_estimators': 452, 'learning_rate': 0.16099151581291948, 'num_leaves': 298, 'max_depth': 45, 'min_child_samples': 68, 'subsample': 0.7202923786890069, 'colsample_bytree': 0.8473606931183613, 'class_weight': {0: 5, 1: 1}}. Best is trial 6 with value: 0.21382228490832159.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:16:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run invincible-newt-620 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/6925ed7ec3f04cd58f10fe3d153d290d\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:17:23,097] Trial 9 finished with value: 0.2709433962264151 and parameters: {'n_estimators': 354, 'learning_rate': 0.110593594614525, 'num_leaves': 212, 'max_depth': 11, 'min_child_samples': 84, 'subsample': 0.6077242239184953, 'colsample_bytree': 0.7543627379257855, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:17:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run polite-fawn-548 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/bc3e290f3da24bddbf2e65040265f383\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:18:07,933] Trial 10 finished with value: 0.2120701754385965 and parameters: {'n_estimators': 245, 'learning_rate': 0.44401230168971517, 'num_leaves': 195, 'max_depth': 3, 'min_child_samples': 43, 'subsample': 0.6011538430977207, 'colsample_bytree': 0.6923255419298138, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:18:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run placid-croc-320 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/04468dd71d684b6bbf35f9fec2373021\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:19:10,517] Trial 11 finished with value: 0.24196443139174417 and parameters: {'n_estimators': 291, 'learning_rate': 0.04032196943507167, 'num_leaves': 121, 'max_depth': 22, 'min_child_samples': 79, 'subsample': 0.8624507161717218, 'colsample_bytree': 0.7712371258721815, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:19:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run delicate-snail-32 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/4924e5dcbe22456ea54630c399c1ca81\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:20:12,895] Trial 12 finished with value: 0.2631483824326767 and parameters: {'n_estimators': 283, 'learning_rate': 0.06770719996893305, 'num_leaves': 129, 'max_depth': 18, 'min_child_samples': 84, 'subsample': 0.8544284003827926, 'colsample_bytree': 0.8569945490313634, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:20:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run calm-skunk-894 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/a3381df7f05b4d14b461f714f0df36f7\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:20:53,901] Trial 13 finished with value: 0.233015773856005 and parameters: {'n_estimators': 57, 'learning_rate': 0.07670215389688408, 'num_leaves': 223, 'max_depth': 22, 'min_child_samples': 86, 'subsample': 0.8508007065880768, 'colsample_bytree': 0.8651525016815726, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:21:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run trusting-shad-125 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/ba8dcbdbd4b24672bda1a0f1d6b175a1\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:21:54,927] Trial 14 finished with value: 0.24920235096557514 and parameters: {'n_estimators': 262, 'learning_rate': 0.07217719452049637, 'num_leaves': 119, 'max_depth': 23, 'min_child_samples': 96, 'subsample': 0.7042317986104475, 'colsample_bytree': 0.7051306879846424, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:22:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bemused-foal-852 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/a5f2d0ef52e34796b40102f09246b639\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:22:57,976] Trial 15 finished with value: 0.26474872541879096 and parameters: {'n_estimators': 313, 'learning_rate': 0.09417598340315711, 'num_leaves': 122, 'max_depth': 12, 'min_child_samples': 58, 'subsample': 0.8259475786058535, 'colsample_bytree': 0.8397467524894888, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:23:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run adorable-grouse-5 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/d63e058c3a04417a92c51de8509a4abd\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:24:02,862] Trial 16 finished with value: 0.26022040526128687 and parameters: {'n_estimators': 373, 'learning_rate': 0.10107643737304617, 'num_leaves': 71, 'max_depth': 30, 'min_child_samples': 40, 'subsample': 0.6571317240115849, 'colsample_bytree': 0.7945716593556285, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:24:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bald-moth-593 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/dd0bcf1bc05a4e969053ac74889971b4\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:24:56,788] Trial 17 finished with value: 0.24494530991050711 and parameters: {'n_estimators': 205, 'learning_rate': 0.042850846007322266, 'num_leaves': 216, 'max_depth': 12, 'min_child_samples': 52, 'subsample': 0.7852561943199883, 'colsample_bytree': 0.9184877972507806, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:25:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run suave-shrimp-118 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/d2d3ef864fa5419fb3e706950229fbcc\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:26:06,442] Trial 18 finished with value: 0.15519056643503895 and parameters: {'n_estimators': 328, 'learning_rate': 0.3299520025677696, 'num_leaves': 159, 'max_depth': 33, 'min_child_samples': 32, 'subsample': 0.8192238151476868, 'colsample_bytree': 0.724591687055901, 'class_weight': {0: 5, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 2, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 5, 1: 1} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:26:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run rogue-wasp-598 at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/8cddb9acf05e410dba18defa2c2fda25\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:27:02,627] Trial 19 finished with value: 0.03199796962242786 and parameters: {'n_estimators': 412, 'learning_rate': 0.017296640985136242, 'num_leaves': 83, 'max_depth': 3, 'min_child_samples': 61, 'subsample': 0.7438999929173415, 'colsample_bytree': 0.6499109778125517, 'class_weight': {0: 1, 1: 1}}. Best is trial 9 with value: 0.2709433962264151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5083526, number of negative: 5083526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 10167052, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026/01/17 11:27:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "d:\\accredian\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 354, 'learning_rate': 0.110593594614525, 'num_leaves': 212, 'max_depth': 11, 'min_child_samples': 84, 'subsample': 0.6077242239184953, 'colsample_bytree': 0.7543627379257855, 'class_weight': {0: 5, 1: 1}}\n",
      "üèÉ View run LightGBM_Run at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6/runs/3138f215fd7149a7a55685a1ca5da6a3\n",
      "üß™ View experiment at: https://dagshub.com/Pranay5519/fraud_detection.mlflow/#/experiments/6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.read_csv(r\"D:\\accredian\\data\\cleaned_fraud.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "# ------------------------------\n",
    "# 2. ENCODE CATEGORICAL COLUMN\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DEFINE X AND y\n",
    "# ------------------------------\n",
    "\n",
    "X = df.drop(columns=['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "# ------------------------------\n",
    "# 4. TRAIN‚ÄìTEST SPLIT\n",
    "# ------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. SCALE FEATURES\n",
    "# (not mandatory for LGBM, kept for consistency)\n",
    "# ------------------------------\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. SMOTE (TRAIN ONLY)\n",
    "# ------------------------------\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# ------------------------------\n",
    "# 7. MLFLOW SETUP\n",
    "# ------------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Pranay5519/fraud_detection.mlflow\")\n",
    "mlflow.set_experiment(\"Fraud_LightGBM_Optuna Exp2\")\n",
    "\n",
    "mlflow.lightgbm.autolog(disable=False)\n",
    "\n",
    "# ------------------------------\n",
    "# 8. OPTUNA OBJECTIVE FUNCTION\n",
    "# ------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.5, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 70),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"class_weight\": trial.suggest_categorical(\n",
    "            \"class_weight\",\n",
    "            [{0: 1, 1: 1}, {0: 2, 1: 1}, {0: 5, 1: 1}]\n",
    "        ),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # ---------- Classification Report ----------\n",
    "        report = classification_report(\n",
    "            y_test,\n",
    "            y_test_pred,\n",
    "            output_dict=True,\n",
    "            zero_division=0\n",
    "        )\n",
    "        # log accuracy score\n",
    "        mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_test_pred))\n",
    "        # ---------- Log metrics ----------\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Optuna optimization target ‚Üí FRAUD PRECISION\n",
    "        return report[\"1\"][\"precision\"]\n",
    "\n",
    "# ------------------------------\n",
    "# 9. RUN OPTUNA STUDY\n",
    "# ------------------------------\n",
    "\n",
    "with mlflow.start_run(run_name=\"LightGBM_Run\"):\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    mlflow.log_params(\n",
    "        {f\"best_{k}\": v for k, v in study.best_params.items()}\n",
    "    )\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # --------------------------\n",
    "    # 10. TRAIN FINAL MODEL\n",
    "    # --------------------------\n",
    "\n",
    "    final_model = lgb.LGBMClassifier(\n",
    "        **best_params,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    final_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    y_test_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "    final_report = classification_report(\n",
    "        y_test,\n",
    "        y_test_pred,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    # log accuracy score\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_test_pred))\n",
    "    for label, metrics in final_report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "                #mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "    print(\"Best Params:\", best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
